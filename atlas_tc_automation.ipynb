{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import openai python package. Please install it with `pip install openai`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/SUDZ4DEV/servicenow-architect-toolz/sat_venv/lib/python3.11/site-packages/langchain/llms/openai.py:264\u001b[0m, in \u001b[0;36mBaseOpenAI.validate_environment\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 264\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mopenai\u001b[39;00m\n\u001b[1;32m    266\u001b[0m     values[\u001b[39m\"\u001b[39m\u001b[39mclient\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39mCompletion\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m api_key \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\u001b[39m\"\u001b[39m\u001b[39mOPENAI_API_KEY\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[39m# Initialize LLM\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m llm \u001b[39m=\u001b[39m OpenAI(model_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtext-davinci-003\u001b[39;49m\u001b[39m\"\u001b[39;49m, model_kwargs\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mapi_key\u001b[39;49m\u001b[39m\"\u001b[39;49m: api_key})\n\u001b[1;32m     20\u001b[0m \u001b[39m# Prompt template\u001b[39;00m\n\u001b[1;32m     21\u001b[0m prompt \u001b[39m=\u001b[39m PromptTemplate( \u001b[39m# IMPORTANT - the prompt template expects a variable named \"daily_objectives\". This is the variable that will be used in the prompt template.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     input_variables\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mdaily_objectives\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     23\u001b[0m     template\u001b[39m=\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m     32\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/SUDZ4DEV/servicenow-architect-toolz/sat_venv/lib/python3.11/site-packages/langchain/load/serializable.py:74\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 74\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lc_kwargs \u001b[39m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/Desktop/SUDZ4DEV/servicenow-architect-toolz/sat_venv/lib/python3.11/site-packages/pydantic/main.py:339\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/SUDZ4DEV/servicenow-architect-toolz/sat_venv/lib/python3.11/site-packages/pydantic/main.py:1102\u001b[0m, in \u001b[0;36mpydantic.main.validate_model\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/SUDZ4DEV/servicenow-architect-toolz/sat_venv/lib/python3.11/site-packages/langchain/llms/openai.py:268\u001b[0m, in \u001b[0;36mBaseOpenAI.validate_environment\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m    266\u001b[0m     values[\u001b[39m\"\u001b[39m\u001b[39mclient\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39mCompletion\n\u001b[1;32m    267\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m--> 268\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m    269\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCould not import openai python package. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    270\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease install it with `pip install openai`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    271\u001b[0m     )\n\u001b[1;32m    272\u001b[0m \u001b[39mif\u001b[39;00m values[\u001b[39m\"\u001b[39m\u001b[39mstreaming\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mand\u001b[39;00m values[\u001b[39m\"\u001b[39m\u001b[39mn\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    273\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot stream results when n > 1.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: Could not import openai python package. Please install it with `pip install openai`."
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# PROJECT BILLABLE HOURS DAYS\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load API key\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Get API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize LLM\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", model_kwargs={\"api_key\": api_key})\n",
    "\n",
    "# Prompt template\n",
    "prompt = PromptTemplate( # IMPORTANT - the prompt template expects a variable named \"daily_objectives\". This is the variable that will be used in the prompt template.\n",
    "    input_variables=[\"daily_objectives\"],\n",
    "    template=\"\"\"\n",
    "    Daily Objectives:\n",
    "    {daily_objectives} \n",
    "    In order to help me fill out my timecard more quickly as a ServiceNow Solution Architect,\n",
    "    Please generate Daily Accomplishments for each of these objectives.\n",
    "    -I also want you to correct any grammar and perform necessary sentence completion on the input (Daily Objective).\n",
    "    -Also, get creative with your response (output of Daily Accomplishments).\n",
    "    \n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Create the LLM chain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# ENTER Daily Objectives for today\n",
    "daily_objectives = \"\"\"\n",
    "Daily Objectives:\n",
    "1. QA Functional requirements CMDB section.\n",
    "2. QA Functional requirements SOC compliance section.\n",
    "3. Finish technical specs for SOC compliance section.\n",
    "4. Finish DPM mapping for UKG Products.\n",
    "\"\"\"\n",
    "\n",
    "# Get the response from the model\n",
    "response = chain.run({\"daily_objectives\": daily_objectives})\n",
    "\n",
    "# Remove leading and trailing white spaces from both daily objectives and response\n",
    "daily_objectives = daily_objectives.strip()\n",
    "response = response.strip()\n",
    "\n",
    "# Format the output\n",
    "output = f'Daily Objectives:\\n{daily_objectives}\\n\\nDaily Accomplishments:\\n{response}\\n'\n",
    "\n",
    "# Save the output to a .txt file\n",
    "with open(\"timecard_entry.txt\", \"w\") as f:\n",
    "    f.write(output)\n",
    "\n",
    "print(\"Timecard entry saved to 'timecard_entry.txt'\")\n",
    "print(output) # print to terminal\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sat_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
